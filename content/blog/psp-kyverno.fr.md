---
Title: "G√©rer ses Policies sur Kubernetes avec Kyverno"
Date: 2021-02-24
Category: Kubernetes
Summary: Les PSP sont en voie de disparition, regardons comment automatiser l'application des best practices Kubernetes gr√¢ce √† Kyverno
Author: Theo "Bob" Massard
image: images/thumbnails/kyverno.png
imgSocialNetwork: images/og/kubefed-eks.png
lang: fr
---

D√©j√† mentionn√© dans [notre article][article-psp-deprecated] qui annon√ßait la d√©pr√©ciation des PodSecurityPolicies et leur
suppression √† partir de la version 1.25, [Kyverno][kyverno-home] s'annonce √™tre un digne successeur √† 
ces derni√®res.

Pour rappel, les PSP permettaient aux administrateurs de cluster de forcer l'application de bonnes pratiques
en d√©finissant un ensemble de r√®gles qui √©taient ex√©cut√©es lors de la phase d'admission, au moyen
d'un Admission Controller _compiled-in_.

Par exemple, les policies peuvent servir √†:
- Forcer la mise en place de labels afin d'harmoniser la gestion de vos ressources
- Restreindre la surface d'attaque en interdisant de monter des `hostPath`
- Emp√™cher un Pod d'utiliser des `hostPort`
- Mettre en place des valeurs par d√©faut pour les limitations de ressource

Dans cet article, nous verrons comment mettre en place Kyverno, d√©couvrir ses fonctionnalit√©s
et explorer ce que nous offre cette m√©thode de gestion des Policies.

### Qu'est-ce que Kyverno ?

Kyverno est un _moteur de gestion de Policies_, permettant de d√©finir des r√®gles en tant que ressources Kubernetes.
Une fois install√©, Kyverno va analyser chaque ressource et appliquer les r√®gles correspondantes.

Site: <https://kyverno.io/>

Afin d'avoir un comportement similaire, Kyverno intervient de la m√™me fa√ßon que les PSP mais au moyen
d'un Admission Controller dynamique qui traite des callbacks (webhooks d'admissions)
de validation et de mutation en provenance de l'apiserver Kubernetes.

Les `Policies` Kyverno sont d√©coup√©es en 3 parties:
- Les r√®gles, ayant chacune un selecteur et une action
- Le selecteur de ressource de la r√®gle, en inclusion ou en exclusion,
- L'action de la r√®gle, qui peut √™tre une validation, une mutation ou une g√©n√©ration de ressource

_R√©f√©rence: [Kyverno - Policy Structure](https://kyverno.io/docs/writing-policies/structure/)._

Elles peuvent √™tre appliqu√©es au niveau d'un Namespace (`Policy`) ou du Cluster (`ClusterPolicy`).
Ces deux ressources g√©n√®rent des `PolicyReports` (ou des `ClusterPolicyReports`) se basant sur le
sch√©ma propos√© dans la [Kubernetes Policy WG][kube-policy-wg].

### Mise en place de Kyverno

#### Installation

Commen√ßons par mettre en place un environnement pour explorer les possibilit√©s de Kyverno!
En utilisant **kind** (pr√©sent√© sur [notre blog][article-kube-local] !), configurons un cluster local:

```console
$ kind create cluster --name kyverno
Creating cluster "kyverno" ...
 ‚úì Ensuring node image (kindest/node:v1.20.2) üñº
 ‚úì Preparing nodes üì¶
 ‚úì Writing configuration üìú
 ‚úì Starting control-plane üïπÔ∏è
 ‚úì Installing CNI üîå
 ‚úì Installing StorageClass üíæ
Set kubectl context to "kind-kyverno"
You can now use your cluster with:

kubectl cluster-info --context kind-kyverno

Thanks for using kind! üòä
```

Il existe diff√©rentes m√©thodes d'installation pour mettre en place Kyverno, utilisons le
Chart Helm officiel pour bootstrapper notre cluster.

```console
$ helm repo add kyverno https://kyverno.github.io/kyverno/
$ helm repo update
$ helm install kyverno kyverno/kyverno --namespace kyverno --create-namespace
NAME: kyverno
LAST DEPLOYED: Wed Feb 24 11:10:31 2021
NAMESPACE: kyverno
STATUS: deployed
REVISION: 1
TEST SUITE: None
NOTES:
Thank you for installing kyverno üòÄ

Your release is named kyverno.

We have installed the "default" profile of Pod Security Standards and set them in audit mode.

Visit https://kyverno.io/policies/ to find more sample policies.
```

Apr√®s quelques secondes, nous avons un cluster configur√© avec un profile de s√©curit√© par d√©faut en mode *audit*
impl√©mentant des r√®gles bas√©es sur les [Pod Security Standards][kube-pss].


#### Bootstrapping

Nous pouvons lister les CRDs install√©s par le chart Helm:
```
$ kubectl api-resources --api-group kyverno.io
NAME                          SHORTNAMES   APIVERSION            NAMESPACED   KIND
clusterpolicies               cpol         kyverno.io/v1         false        ClusterPolicy
clusterreportchangerequests   crcr         kyverno.io/v1alpha1   false        ClusterReportChangeRequest
generaterequests              gr           kyverno.io/v1         true         GenerateRequest
policies                      pol          kyverno.io/v1         true         Policy
reportchangerequests          rcr          kyverno.io/v1alpha1   true         ReportChangeRequest
$ kubectl api-resources --api-group wgpolicyk8s.io
NAME                   SHORTNAMES   APIVERSION                NAMESPACED   KIND
clusterpolicyreports   cpolr        wgpolicyk8s.io/v1alpha1   false        ClusterPolicyReport
policyreports          polr         wgpolicyk8s.io/v1alpha1   true         PolicyReport
```

Les r√®gles du profile "default" sont d√©finies via des `ClusterPolicies`:
```
$ kubectl get cpol -n kyverno
NAME                             BACKGROUND   ACTION
disallow-add-capabilities        true         audit
disallow-host-namespaces         true         audit
disallow-host-path               true         audit
disallow-host-ports              true         audit
disallow-privileged-containers   true         audit
disallow-selinux                 true         audit
require-default-proc-mount       true         audit
restrict-apparmor-profiles       true         audit
restrict-sysctls                 true         audit
```

En effet, nous avons d√©j√† un bon nombre de `Policies` ! Cependant, pas d'inqui√©tude.
Nous pouvons observer qu'elles ont toutes √©t√© d√©finies avec `background=true` et `action=audit`.
Cette configuration indique √† Kyverno que ces r√®gles ne doivent pas √™tre bloquantes.
Toutes les 15 minutes, une analyse est lanc√©e pour chaque r√®gle sur les ressources
pr√©sentes √† cet instant au sein du Cluster et g√©n√®rent des ClusterPolicyReports.

### Exemples d'utilisation

#### Cr√©ation d'une ClusterPolicy

Il est temps de mettre en place notre premi√®re `Policy` ! 
D√©finissons une r√®gle simple qui v√©rifie la pr√©sence d'un label identifiant
le nom de l'application √† laquelle un `Pod` correspond.

```yaml
---
apiVersion: kyverno.io/v1
kind: ClusterPolicy
metadata:
  name: require-labels
spec:
  validationFailureAction: enforce
  rules:
    - name: check-for-label-name
      match:
        resources:
          kinds:
            - Pod
      validate:
        message: "label `app.kubernetes.io/name` is required"
        pattern:
          metadata:
            labels:
              app.kubernetes.io/name: "?*"
```

La r√®gle `check-for-label-name` permet de consid√©rer comme pr√©requis le label
`app.kubernetes.io/name` pour le d√©ploiement des ressources de type `Pod`.

Pour r√©sumer cette r√®gle:

_Il est obligatoire pour tout `Pod` d'avoir un label `app.kubernetes.io/name` d'une longueur sup√©rieure ou √©gale √† 1 caract√®re._

Apr√®s avoir appliqu√© notre `ClusterPolicy`, nous obtenons la ressource suivante:

```yaml
---
apiVersion: kyverno.io/v1
kind: ClusterPolicy
metadata:
  name: require-labels
  annotations:
    pod-policies.kyverno.io/autogen-controllers: DaemonSet,Deployment,Job,StatefulSet,CronJob
spec:
  background: true
  rules:
    - match:
      resources:
        kinds:
          - Pod
      name: check-for-label-name
      validate:
        message: label `app.kubernetes.io/name` is required
      pattern:
        metadata:
          labels:
            app.kubernetes.io/name: ?*
    - match:
      resources:
        kinds:
          - DaemonSet
          - Deployment
          - Job
          - StatefulSet
      name: autogen-check-for-label-name
      validate:
        message: label `app.kubernetes.io/name` is required
        pattern:
          spec:
            template:
              metadata:
                labels:
                  app.kubernetes.io/name: ?*
    - match:
      resources:
        kinds:
          - CronJob
      name: autogen-cronjob-check-for-label-name
      validate:
        message: label `app.kubernetes.io/name` is required
        pattern:
          spec:
            jobTemplate:
              spec:
                template:
                  metadata:
                    labels:
                      app.kubernetes.io/name: ?*
      validationFailureAction: enforce
```

On retrouve notre r√®gle "check-for-label-name", mais deux autres r√®gles ont √©t√© autog√©n√©r√©es
afin d'appliquer le comportement que nous souhaitons aux autres ressources permettant
de d√©finir des pods.

Ces r√®gles sont cr√©√©es par les `autogen-controllers` ([link][kyverno-autogen]) r√©f√©renc√©s par
l'annotation correspondante qui sert d'annotation par d√©faut. D√©finir manuellement cette annotation permet de
modifier le comportement de g√©n√©ration automatique de r√®gles.

Essayons de d√©ployer une ressource qui enfreint la r√®gle que nous venons de cr√©er:
```
$ kubectl run sample --image=busybox 
Error from server: admission webhook "validate.kyverno.svc" denied the request: 

resource Pod/default/sample was blocked due to the following policies

require-labels:
  check-for-labels: 'validation error: label `app.kubernetes.io/name` is required. Rule check-for-label-name failed at path /metadata/labels/app.kubernetes.io/name/'
$ kubectl run sample --image=busybox  --labels app.kubernetes.io/name=valid
pod/sample created
```

Notre `Policy` a une `validationFailureAction=enforce`, il nous est donc impossible de cr√©er une
ressource ne validant pas l'int√©gralit√© des r√®gles d√©finies!

Apr√®s avoir ajout√© un label pour le nom de notre `Pod`, le webhook d'admission Kyverno
valide la requ√™te et la ressource est cr√©√©e.

#### Le mode "audit"

Lors du d√©ploiement du Chart Helm, un profil par d√©faut a √©t√© configur√© en mode audit.

_We have installed the "default" profile of Pod Security Standards and set them in audit mode._

Ce mode de validation de `Policy` est _non-intrusif_ et permet de mettre progressivement
en application les r√®gles. Il n'emp√™che pas la cr√©ation des ressources qui ne sont pas conformes 
√† la `Policy` mais va historiser les infractions dans des `PolicyReport` (`polr`) si la
ressource est _namespaced_ (comme un `Deployment` ou un `ConfigMap`) dans le namespace de la ressource, 
ou des `ClusterPolicyReports` (`cpolr`) s'il s'agit de ressource non _namespaced_ (un `Namespace`)

Lors de la cr√©ation d'un `Deployment`, le template du `Pod` enfreint une `ClusterPolicy`.
L'infraction sera report√©e dans une `PolicyReport` dans le namespace du `Pod`.

Lors de la cr√©ation d'une `IngressClass`, l'absence de label enfreint une autre `ClusterPolicy`.
L'infraction sera report√©e dans une `ClusterPolicyReport`.

Comme mentionn√© pr√©c√©demment, le mode audit va p√©riodiquement (toutes les 15 minutes)
analyser les ressources et g√©n√©rer des reports.

Configurons une `Policy` en mode audit ainsi qu'un `Pod` de test:

```yaml
---
apiVersion: kyverno.io/v1
kind: ClusterPolicy
metadata:
  name: require-tier-on-pod
spec:
  validationFailureAction: audit
  background: true
  rules:
    - name: check-for-tier-on-pod
      match:
        resources:
          kinds:
            - Pod
      validate:
        message: "if set, label `app.kubernetes.io/tier` must be any of ['frontend', 'backend', 'internal']"
        pattern:
          metadata:
            labels:
              =(app.kubernetes.io/tier): "frontend | backend | internal"
---
apiVersion: v1
kind: Pod
metadata:
  labels:
    app.kubernetes.io/tier: uknown
    app.kubernetes.io/name: example-pod
  name: bad-tier
spec:
  containers:
    - image: nginx:latest
      name: example-tier
```
_Si le label `app.kubernetes.io/tier` existe, il doit correspondre √† l'une des valeurs frontend, backend ou internal._

Apr√®s quelques instants, nous pouvons observer un avertissement venant de l'admission-controller:
```
$ kubectl describe pod bad-tier  | grep -A 5 Events
Events:
  Type     Reason           Age   From                  Message
  ----     ------           ----  ----                  -------
  Warning  PolicyViolation  8s   admission-controller  Rule(s) 'check-for-tier-on-pod' of policy 'require-tier-on-pod' failed to apply on the resource
  Normal   Scheduled        8s   default-scheduler     Successfully assigned default/bad-tier to kyverno-control-plane
  Normal   Pulling          7s   kubelet               Pulling image "nginx:latest"
$ kubectl get polr
NAME              PASS   FAIL   WARN   ERROR   SKIP   AGE
polr-ns-default   1      1      0      0       0      30m
```

Nous pouvons obtenir un _report_ complet en effectuant un _describe_ sur le `PolicyReport`
du `Namespace` correspondant.

```yaml
---
apiVersion: wgpolicyk8s.io/v1alpha1
kind: PolicyReport
metadata:
  name: polr-ns-default
  namespace: default
results:
  - message: 'validation error: if set, label `app.kubernetes.io/tier` must be any of
    [''frontend'', ''backend'', ''internal'']. Rule check-for-tier-on-pod failed at
    path /metadata/labels/app.kubernetes.io/tier/'
    policy: require-tier-on-pod
    resources:
      - apiVersion: v1
        kind: Pod
        name: bad-tier
        namespace: default
        uid: 6e743322-5b2a-4ad7-bc79-eca437ab82db
    rule: check-for-tier-on-pod
    scored: true
    status: fail
  - category: Pod Security Standards (Default)
    message: validation rule 'host-namespaces' passed.
    policy: disallow-host-namespaces
    resources:
      - apiVersion: v1
        kind: Pod
        name: sample
        namespace: default
        uid: 19dc0c5b-3960-4178-8bb0-6cd61a23c089
    rule: host-namespaces
    scored: true
    status: pass
summary:
  error: 0
  fail: 1
  pass: 1
  skip: 0
  warn: 0
```

Les `PolicyReports` permettent d'avoir une vue d'ensemble des infractions
locales au namespace dans lequel elles r√©sident.

Chaque report inclut un r√©capitulatif de l'application des r√®gles avec le nombre
d'infraction, de validation, d'avertissements, ...

### Comment impl√©menter Kyverno

#### Lors de la mise en place d'un Cluster

Afin de partir sur de bonnes bases, vous pouvez int√©grer Kyverno √† votre Cluster Kubernetes
apr√®s sa cr√©ation en surchargeant [les valeurs par d√©faut][kyverno-chart-values] du Chart Helm.

Une version plus s√©curis√©e du profile "[default][kyverno-psp-default]" est disponible via
le profile "[restricted][kyverno-psp-restricted]" et peut √™tre accompagn√©e d'un
`validationFailureAction=enforce` afin de garantir l'int√©grit√© et la s√©curit√© du cluster.

#### Dans un Cluster existant

Il est totalement possible d'ajouter Kyverno √† une configuration en utilisant le m√™me proc√©d√©.
Attention cependant √† ne pas enforce les Policies que vous mettez en place de fa√ßon √†
ne pas cause d'interruption.

Une transition vers des ressources conformes aux r√®gles que vous souhaitez d√©finir pourrait s'effectuer de
en utilisant la m√©thode suivante:
- D√©finition des r√®gles √† impl√©menter via Kyverno en mode audit
- Observer les infractions via les PolicyReports et les ClusterPolicyReports
- Ajout d'une √©tape de validation dans les CI/CD via [Kyverno CLI][kyverno-cli]
- Passage en mode "enforce" lorsque les ressources sont conformes √† la Policy

### Conclusion

La mise en place d'une solution de gestion de Policy est une √©tape importante
concernant la s√©curisation des clusters Kubernetes.

Kyverno r√©ussit √† r√©pondre √† cette probl√©matique d'une mani√®re √©l√©gante et peut se r√©v√©ler
√™tre un excellent rempla√ßant aux PSP. La dimension _Kubernetes Native_ rend la courbe
d'apprentissage tr√®s douce, ne n√©cessitant pas d'apprendre de nouvelle syntaxe.

Dans cet article, nous avons couvert les similarit√©s au niveau des PSP. Cependant,
Kyverno propose des fonctionnalit√©s additionnelles, telle que la [mutation][kyverno-policies-mutate]
de ressources permettant de rajouter des valeurs par d√©fauts, ou encore la [g√©n√©ration][kyverno-policies-validate]
de ressources qui offre la possibilit√© de r√©pliquer des ressources √† travers diff√©rents namespaces
ou d'automatiser certaines op√©rations.

[**Theo "Bob" Massard**](https://www.linkedin.com/in/tbobm/), Cloud Native Engineer

[article-kube-local]: https://particule.io/blog/kubernetes-local/
[article-psp-deprecated]: https://particule.io/blog/kubernetes-psp-deprecated/
[kube-policy-wg]: https://github.com/kubernetes-sigs/wg-policy-prototypes/tree/master/policy-report
[kube-pss]: https://kubernetes.io/docs/concepts/security/pod-security-standards/
[kyverno-autogen]: https://kyverno.io/docs/writing-policies/autogen/
[kyverno-chart-values]: https://github.com/kyverno/kyverno/blob/main/charts/kyverno/values.yaml
[kyverno-cli]: https://kyverno.io/docs/kyverno-cli/
[kyverno-home]: https://kyverno.io/
[kyverno-policies-mutate]: https://kyverno.io/docs/writing-policies/mutate/
[kyverno-policies-validate]: https://kyverno.io/docs/writing-policies/validate/
[kyverno-psp-default]: https://kyverno.io/policies/pod-security/default/
[kyverno-psp-restricted]: https://kyverno.io/policies/pod-security/restricted/
